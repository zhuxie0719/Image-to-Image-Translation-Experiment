# 课程实验任务书：图像到图像生成实验（以城市街景为例）

## 一、实验背景与目标

随着生成模型（Generative Models）与深度学习技术的快速发展，图像到图像转换（Image-to-Image Translation）已成为计算机视觉中的核心研究方向之一。其目标是学习从一种视觉域（如语义标签、边缘、深度图、素描）到另一种视觉域（如真实图像、彩色渲染、风格图像）的映射关系。该方向起源于 Pix2Pix（Conditional GAN），并发展出众多变体：如 CycleGAN、Pix2PixHD、StyleGAN-T、Diffusion 模型等。学生将以 Cityscapes 城市街景数据集为基础，从语义标签图生成真实街景照片，探索多种图像生成模型在结构保持与真实感生成间的平衡。

- 实验目标：

1\. 理解不同类型图像生成模型（GAN、Diffusion、VAE 等）的原理与训练机制；

2\. 掌握一种模型并完成该从语义标签图生成真实街景照片的任务

3\. 探索不同损失项（L1、Adversarial、Feature Matching、Perceptual Loss 等）对生成质量的影响；

4\. 掌握常用图像生成质量评价指标（PSNR、SSIM、MAE、FID），并进行结果可视化与分析。

## 二、实验任务与内容

1\. 数据准备：

数据集下载地址：https://gitcode.com/open-source-toolkit/04615

数据集为 Cityscapes 格式拼接图像：每张图片左侧为真实街景（photo），右侧为语义标签（label）。

2\. 模型选择（可任选或对比）：

可选模型包括 Pix2Pix、CycleGAN、StyleGAN、Stable Diffusion、U-Net等。

3\. 训练与可视化：

任务方向：Label → Photo；

每个 epoch 保存验证集的三联图（Label / Generated / Ground Truth），记录 PSNR、SSIM、MAE、FID 等指标。

## 三、实验环境与依赖

Python ≥ 3.8

PyTorch ≥ 1.12

CUDA ≥ 11.3

tqdm, Pillow, torchvision, numpy, scikit-image, matplotlib

## 四、评估指标

|     |     |     |
| --- | --- | --- |
| 指标  | 含义  | 说明  |
| PSNR | 峰值信噪比 | 衡量生成图与真实图的像素误差 |
| SSIM | 结构相似性 | 衡量结构一致性与纹理保真度 |
| MAE | 平均绝对误差 | 衡量像素级平均偏差 |
| FID | 感知质量 | 衡量生成分布与真实分布的距离 |
| 主观质量 | 人眼观察结果 | 用于补充客观指标 |

## 五、实验报告要求

1\. 说明实验环境、模型配置与参数设置；

2\. 展示训练过程曲线与生成样例；

3\. 对比不同模型或损失函数（如 L1 vs L1+GAN vs Diffusion）；

4\. 分析结果差异并总结结论。

## 六、实验评分标准

|     |     |
| --- | --- |
| 项目  | 说明  |
| 实验完整性 | 代码可运行、能生成合理结果 |
| 结果分析与指标对比 | 有对比、有结论 |
| 报告质量 | 逻辑清晰、图文并茂 |
| 创新尝试 | 尝试新损失/模型/扩散方法 |
| 生成效果 | 生成结果质量高 |

## 七、提交内容

1\. 训练代码；

2\. 验证集生成结果样例（三联图）；

3\. 实验报告（PDF 格式）；

DDL:12.28日

[作业2的实验报告等材料最终发送至到guangyu.ryan@yahoo.com](mailto:作业1的实验报告等材料最终发送至到guangyu.ryan@yahoo.com)

参考文献：

Image-to-Image Translation with Conditional Adversarial Networks（CVPR2017）

Github仓库：[phillipi/pix2pix: Image-to-image translation with conditional adversarial nets](https://github.com/phillipi/pix2pix)