---
date: 2024-12-22
author: 学生
summary: Pix2Pix E2（50 epoch，L1+GAN, strong 增强）训练与 L1 vs L1+GAN 对比实验 E5
---

## 1. 今日工作概览（2024-12-22）

- **E2 进展**：在 Google Colab 上完成 Pix2Pix（L1 + GAN，strong 增强）训练 50 epoch，并将 `outputs/pix2pix_l1_gan_strong_e50` 中的所有日志、checkpoint 和样例图完整保存到 Google Drive，随后下载回本地。
- **E2 结果整理**：在本地编写并运行脚本 `src/eval/plot_pix2pix_e2.py`，基于 `history_pix2pix.json` 生成 E2 的损失曲线、指标曲线和主结果表，并统一整理 Pix2Pix 的样例三联图。
- **E5 实验**：基于已有的 U-Net 基线（E1，strong 增强）和 Pix2Pix（E2）结果，完成 **L1 vs L1+GAN 损失对比实验 E5**，包括数值对比表、柱状图和样例图对比。

---

## 2. 实验 E2：Pix2Pix（L1 + GAN, strong 增强）50 epoch

### 2.1 实验配置（参考 `outputs/pix2pix_l1_gan_strong_e50/config.json`）

- **模型**：Pix2Pix（U-Net 生成器 + PatchGAN 判别器）
- **损失函数**：
  - 生成器：`L_G = L_GAN + λ * L_L1`，其中 `λ = 100`
  - 判别器：标准对抗损失（真实/生成 patch 的 BCE）
- **数据与增强**：
  - 数据集：Cityscapes label → photo，train/val 划分同前
  - 增强策略：`strong` 模式（随机 jitter + 随机翻转 + 颜色抖动等）
- **训练超参数**：
  - Epochs：50（本次在 Colab 上跑到 50 epoch，GPU 配额受限，暂不继续）
  - Batch size：1
  - 优化器：Adam（lr=2e-4，β1=0.5）
  - 输入尺寸：256×256

### 2.2 训练与验证曲线（`e2_pix2pix_losses_e50.png`）

- **生成器总损失 `train_g_total`**：从 ~27 逐渐下降到 ~23.2 左右，在 20 epoch 之后基本进入震荡平台，说明模型已进入收敛期。
- **L1 损失 `train_g_l1`**：从约 0.224 稳定下降到约 0.204 左右，整体呈平滑下降趋势，表示像素级重建误差持续减小。
- **GAN 损失 `train_g_gan`**：从 ~4.7 降到约 2.6–2.8 区间，并在该区间小幅震荡，表明生成器在与判别器对抗中逐渐“变强”，对抗损失进入稳定博弈状态。
- **判别器损失 `train_d`**：从 ~0.15 上升到 ~0.28–0.30，并围绕该区间震荡，未出现过低或爆炸，说明 G 和 D 之间保持了相对平衡。
- **验证 L1 `val_l1`**：从初始约 0.14 降到约 0.11 左右，在 20–50 epoch 区间内小幅波动，没有明显恶化，显示模型在验证集上没有明显过拟合。

**小结**：E2 的损失曲线整体形态健康，训练稳定，Pix2Pix 已在 30 epoch 以后进入“微调阶段”，50 epoch 时已基本收敛。

### 2.3 验证指标曲线（`e2_pix2pix_val_metrics_e50.png`）

- **PSNR 曲线**：
  - 初始约 14.6 dB，随着训练上升到 16 dB 左右；
  - 在 epoch 36 附近达到最高值约 **16.275 dB**，此后在 16.0–16.2 dB 区间轻微波动。
- **SSIM 曲线**：
  - 初始约 0.26，快速提升到 0.40 左右；
  - 在 20–50 epoch 区间稳步上升到 **0.43–0.45**，epoch 50 时约为 **0.449**。
- **MAE/L1 曲线**：
  - 与 `val_l1` 一致，从 ~0.14 降到 ~0.11，后期小幅震荡。

**结论**：E2 的 PSNR/SSIM 曲线显示 Pix2Pix 在 20–30 epoch 后已进入性能平台区，后续 epoch 主要是小幅的精细调整；SSIM 在 36–50 epoch 仍有轻微提升，说明结构和感知质量在缓慢改善。

### 2.4 主结果表（`e2_pix2pix_main_results_e50.md`）

- **表格内容**：

  | 设置 | Epoch | Val L1/MAE ↓ | PSNR ↑ | SSIM ↑ |
  |------|-------|--------------|--------|--------|
  | 最佳 (按最小 Val L1) | 36 | 0.1109 | 16.275 | 0.435 |
  | 最后 (Epoch 50)      | 50 | 0.1122 | 16.150 | 0.449 |

- **分析**：
  - 按最小验证 L1 选取的最佳 epoch 为 **36**，此时 L1 最低，PSNR 也接近全程最高；
  - epoch 50 时，L1 略有回升，但 SSIM 略有上升（0.435 → 0.449），说明最后阶段模型在牺牲少量像素误差的前提下，进一步优化了结构相似度和主观视觉质量。

### 2.5 样例三联图整理

- 使用 `src/eval/plot_pix2pix_e2.py` 中的 `collect_sample_images` 函数，将 `outputs/pix2pix_l1_gan_strong_e50/images/epoch_XXX_sample_YY.png` 统一复制到：
  - `outputs/images/pix2pix_l1_gan_strong_e50/`
- 目前选取的代表性样例：
  - 早期：`epoch_001_sample_00/01.png`
  - 中期：`epoch_020/030/040_sample_00/01.png`
  - 后期：`epoch_050_sample_00/01.png`
- 后续报告中可重点展示 1/20/36/50 epoch 的三联图，对比生成质量随训练进展的变化。

---

## 3. 实验 E5：L1 vs L1+GAN 损失对比

### 3.1 实验目的

- 在相同数据和增强配置（strong）的前提下，对比：
  - **U-Net 基线（仅 L1 损失）** 与
  - **Pix2Pix（L1 + GAN 损失）**
- 重点考察：加入 GAN 损失后，对 **PSNR、SSIM、MAE** 等传统重建指标以及主观生成质量的影响。

### 3.2 使用的结果与脚本

- U-Net（E1）的结果来源：
  - 日志：`outputs/logs/unet_baseline/ablation_results_first40.csv`
  - 图像：`outputs/images/unet_baseline/sample_XX_strong_e040.png`
- Pix2Pix（E2）的结果来源：
  - 主结果表：`outputs/figures/pix2pix_l1_gan_strong_e50/e2_pix2pix_main_results_e50.md`
  - 图像：`outputs/images/pix2pix_l1_gan_strong_e50/epoch_050_sample_XX.png`
- 对比脚本：
  - 新增 `src/eval/compare_e5_l1_vs_gan.py`，自动：
    - 从 U-Net CSV & Pix2Pix MD 中解析关键指标；
    - 生成 E5 对比表和柱状图；
    - 收集一组 U-Net vs Pix2Pix 的样例三联图用于主观对比。

### 3.3 数值结果对比（`e5_l1_vs_l1_gan_table.md`）

| 模型     | 增强   | 选取策略           | Epoch | Val L1/MAE ↓ | PSNR ↑  | SSIM ↑ |
|----------|--------|--------------------|-------|--------------|---------|--------|
| U-Net    | strong | Final (40 epoch)   | 40    | 0.1014       | 17.089  | 0.509  |
| U-Net    | strong | Best PSNR          | 38    | 0.1014       | 17.323  | 0.512  |
| Pix2Pix  | strong | Best Val L1        | 36    | 0.1109       | 16.275  | 0.435  |
| Pix2Pix  | strong | Last (50 epoch)    | 50    | 0.1122       | 16.150  | 0.449  |

**定量结论：**

- 在相近 epoch 设置下（U-Net 40 epoch vs Pix2Pix 50 epoch），**U-Net（仅 L1）在 Val L1/MAE、PSNR 和 SSIM 三个指标上都优于 Pix2Pix（L1+GAN）**：
  - L1/MAE：0.1014（U-Net） < 0.1109 / 0.1122（Pix2Pix）
  - PSNR：约 17.1–17.3 dB（U-Net） > 16.15–16.28 dB（Pix2Pix）
  - SSIM：约 0.51（U-Net） > 0.44（Pix2Pix）
- 说明在当前实验配置和训练轮数下，**引入 GAN 损失并没有提升传统重建指标，反而略有下降**。

### 3.4 指标柱状图（`e5_l1_vs_l1_gan_bar.png`）

- 图中三组柱表示：
  - Val L1/MAE（↓ 更好）
  - PSNR（↑ 更好）
  - SSIM（↑ 更好）
- 对比可以直观看到：
  - U-Net (L1) 的 L1 更低，PSNR/SSIM 更高；
  - Pix2Pix (L1+GAN) 在三个传统指标上均劣于 U-Net。
- 结合 E2 的训练曲线，可以推测：
  - GAN 损失驱动生成器在局部纹理上做更“激进”的调整，这种调整在像素级误差度量（L1、PSNR）下被视作“更差”，因此指标下降；
  - 但这不代表主观视觉一定更差，需要结合样例图分析。

### 3.5 样例图主观对比（`outputs/images/e5_l1_vs_l1_gan/`）

- 当前收集的样例对包括：
  - `unet_sample_00_strong_e040.png` vs `pix2pix_epoch_050_sample_00.png`
  - `unet_sample_01_strong_e040.png` vs `pix2pix_epoch_050_sample_01.png`
- 初步观察（待在报告中配图说明）：
  - **U-Net (L1)**：
    - 轮廓与语义结构整体更加稳定，边界对齐良好，色块干净；
    - 但局部纹理偏平滑，有“磨皮”倾向，细节略显单调。
  - **Pix2Pix (L1+GAN)**：
    - 某些区域（例如路面噪点、建筑纹理、树木结构）的高频纹理更丰富、随机性更强；
    - 但也可能引入伪影或不稳定纹理，使像素误差增大，从而在 L1/PSNR/SSIM 上被“惩罚”。

**主观结论：**

- L1 损失主导的 U-Net 更倾向于“整体平滑、结构正确”的重建；
- L1 + GAN 的 Pix2Pix 更倾向于“局部纹理更像真实照片”，但难以在传统重建指标上获得优势。

### 3.6 E5 小结

- 在 Cityscapes label→photo 任务的当前设置下：
  - **若只看 PSNR / SSIM / MAE 指标，U-Net (L1) 表现优于 Pix2Pix (L1+GAN)**；
  - 加入 GAN 损失会牺牲部分像素级重建精度，换取局部纹理和感知质量的改善，这种改善不一定能在传统指标上体现。
- 后续报告中将把 E1（U-Net）和 E2（Pix2Pix）的结果，与本次 E5 对比实验统一整理到一张“结果汇总表”中，并配合样例三联图展示两种损失策略在**定量指标和定性观感**上的差异。

---

## 4. 明日/后续计划

- 如 Colab GPU 配额恢复：
  - 继续从 `pix2pix_l1_gan_strong_e50` 的 50 epoch checkpoint 进行训练，尝试延长到 100 或 200 epoch，观察 E2 指标是否仍有提升空间。
- 在本地继续：
  - 将 E2 和 E5 的图表与结论整理进最终报告草稿；
  - 规划后续 E6/E7（Feature Matching / Perceptual Loss）以及 CycleGAN 相关实验的最小可行配置。


