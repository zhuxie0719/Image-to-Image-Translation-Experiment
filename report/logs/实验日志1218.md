# 实验日志 2025-12-18（U-Net 数据增强消融收尾 & 40 Epoch 对齐）

## 背景与目标
- 在 12-17 已完成 `none / basic / strong` 三种增强配置下的 **200 epoch** 全量训练，并按照《ABLATION_GUIDE.md》生成了各自的 `history_{aug_mode}.json` 与样例图。
- 其中：
  - `none / basic` 均按照原计划完整跑满 200 epoch，用来观察**长程训练下的收敛极限与过拟合趋势**，为后续“只看前 40 epoch 是否已经足够”提供参照。
  - **strong（强增强）在本地只针对前 40 epoch 做了完整训练与日志记录**，后续将三种配置统一截断到 40 epoch 做公平比较。
- 因此在 12-18 的主要工作是：
  - 基于已有日志，对三种增强方案做 **“前 40 epoch 公平对齐”** 的对比分析；
  - 生成基于 epoch 40 的样例图，用于可视化比较；
  - 补充说明：为什么 `none/basic` 需要跑到 200 epoch，而 strong 只保留 40 epoch 的结果，以及对结论的影响。

> 说明：`none/basic` 的 200 epoch 实验可以看作“上界参考”（在充分训练条件下，各自能到什么水平），而 strong 更关注的是“在合理训练预算内（前 40 epoch）能否显著改善泛化”，两者在本次分析中通过统一截断到 40 epoch 来对齐。

## 操作记录

1. **统一截断到前 40 epoch 的训练历史**
   - 在 `01_unet_baseline.ipynb` 的第 7 节（数据增强消融实验完整流程）中：
     - 增加 `MAX_EPOCHS = 40`，读取 `history_none/basic/strong.json` 后，对 `train_losses / val_losses / val_psnrs / val_ssims / val_maes` 统一调用 `seq[:MAX_EPOCHS]` 截断。
     - 所有对比（损失曲线、指标柱状图、文本报告）均基于截断后的 `histories`，避免 `none/basic` 训练到 200 epoch 而 `strong` 只有 40 epoch 带来的“不公平尾段优势”。
   - 重新生成的图表与报告：
     - `ablation_loss_curves_first40.png`：三种增强在前 40 epoch 的 Train/Val L1 曲线（线性 & log）。
     - `ablation_metrics_comparison_first40.png`：基于各自第 40 epoch 的 Val PSNR / SSIM / MAE 柱状图。
     - `ablation_results_first40.csv`：表格版结果。
     - `ablation_report_first40.txt`：文字总结，强调“所有结论仅基于前 40 epoch”。

2. **按 epoch 40 统一生成样例图**
   - 之前的 `sample_*_{aug_mode}.png` 默认来自训练末尾的若干 epoch，不同配置的 epoch 不完全一致。
   - 在 notebook 中新增小脚本：
     - 从 `outputs/checkpoints/unet_baseline/checkpoint_{aug_mode}_epoch_040.pth` 加载权重（`torch.load(..., weights_only=False)`，兼容 PyTorch 2.6 的新默认行为）。
     - 使用对应增强配置的 `CityscapesDataset(split="val", transform=aug_configs[aug_mode])` 与 `validate` 函数，只跑一次前向，保存 6 张三联图。
     - 命名为 `sample_XX_{aug_mode}_e040.png`，以区分原来的“最终 epoch”样例。
   - 基于这些新样例，修改 “7.5 生成结果可视化对比”：
     - 优先加载 `sample_*_{aug_mode}_e040.png`，若不存在再回退到旧命名。
     - 统一标题为：`Generated Samples Comparison @ Epoch 40: Label | None | Basic | Strong`。
   - 结果上可以清晰看到：
     - **none/basic** 在 40 epoch 时已有一定细节，但噪声较多，整体偏模糊；
     - **strong** 纹理略更稳定、路面和建筑区域更干净，但整体偏暗，存在轻微颜色偏差。

3. **为什么 none / basic 跑满 200 epoch，而 strong 只保留前 40 epoch？**
   - **none/basic 跑 200 epoch 的动机**
     - 作为“弱增强”与“中等增强”的基线配置，需要观察**完整训练过程中的收敛与过拟合行为**，包括：
       - Val L1 在 100 epoch 之后是否还在下降，还是已经进入震荡甚至回升；
       - 长程训练下 PSNR / SSIM 是否仍有提升空间，还是很早就饱和。
     - 200 epoch 的全程曲线为后续分析提供了一个“性能上界”的参考：即使给足训练时间，none/basic 能达到的最好水平大致在哪个区间。
   - **strong 只保留前 40 epoch 的考虑**
     - 从任务角度，希望回答的问题是：“在**相同训练预算**下，增强强度提高是否能明显改善前期泛化？”——对应到具体设置，就是比较三种增强在前 20–40 epoch 内的表现。
     - 在 strong 的实验中，前 40 epoch 的 Val 曲线已经呈现出与 none/basic 明显不同的趋势（下降更快、稳定在更低的损失水平），进一步延长训练主要是在已有优势基础上的细节微调，对结论影响有限。
     - 同时，强增强本身提供了更强的正则化；如果一味长时间训练，反而容易把“正则 + 长程训练”的效果混在一起，不利于分清楚“增强强度”本身带来的收益。因此，本次只保留前 40 epoch 的 strong，用来突出“增强策略”这一变量的影响。
   - **曲线趋势已经足以支撑结论**
     - 在 L1 损失曲线上：
       - `none/basic`：前 40 epoch Val L1 缓慢下降，但整体仍在 ~0.21 上下，后续 160 个 epoch 下降幅度也有限（之前 200 epoch 结果已验证）。
       - `strong`：从 ~0.214 下降到 ~0.200 左右，前 20–40 epoch 内验证集损失有**明显、持续的下降**。
     - 在 PSNR / SSIM 指标上：
       - strong 在 40 epoch 内的峰值 PSNR、MAE 已经略好于 basic，且差距主要体现在早期训练阶段。
     - 因此，即便继续训练到 200 epoch，预期只是对 strong 的结果做小幅 fine-tuning，不会改变“强增强显著改善前期泛化”的主要结论。
   - **实验重点在“增强策略对前期收敛与泛化的影响”**
     - 本次作业目标之一是理解 **数据增强强度对模型泛化的作用机制**，而不是追求绝对最优数值。
     - 将三种增强统一对齐到 **前 40 epoch**，反而更能直观比较：
       - 在相同训练预算下（相同 epoch 数），strong 是否带来更好的验证性能与更稳定的训练曲线。

4. **最终结论（基于前 40 epoch 对齐）**
   - **训练/验证损失**：
     - strong 的 Train/Val L1 均显著低于 none/basic，且 Val loss 在 40 epoch 内仍缓慢下降，尚未出现明显过拟合。
   - **评价指标**：
     - 在 40 epoch 时，strong 的 **Val MAE 最低、PSNR 最高**，SSIM 与 basic 接近。
   - **可视化效果**：
     - strong 生成结果在结构和边缘区域更稳、车道/路面更干净；代价是图像略暗、对比度偏低。
   - 综上，在相同训练轮数下，**强增强在泛化指标和感观质量上均优于无增强/基础增强**，因此后续若叠加 GAN 或感知损失，建议默认采用 strong 配置作为数据增强方案。


