{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAx9wxin4kib"
      },
      "source": [
        "# 01 U-NetåŸºçº¿æ¨¡å‹å®éªŒ\n",
        "\n",
        "## ç›®æ ‡\n",
        "- å®ç°U-NetåŸºçº¿æ¨¡å‹ï¼ˆä»…L1æŸå¤±ï¼Œæ— GANï¼‰\n",
        "- æ•°æ®å¢å¼ºæ¶ˆèå®éªŒï¼ˆæ— å¢å¼ºã€åŸºç¡€å¢å¼ºã€å¼ºå¢å¼ºï¼‰\n",
        "- è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼ˆæŸå¤±æ›²çº¿ã€ä¸‰è”å›¾ï¼‰\n",
        "- è¯„ä¼°æŒ‡æ ‡è®°å½•ï¼ˆPSNRã€SSIMã€MAEï¼‰\n",
        "\n",
        "## æ¨¡å‹æ¶æ„\n",
        "- ä¸Pix2Pixç”Ÿæˆå™¨ç›¸åŒçš„U-Netç»“æ„\n",
        "- ç¼–ç å™¨ï¼šC64-C128-C256-C512-C512-C512-C512-C512\n",
        "- è§£ç å™¨ï¼šCD512-CD512-CD512-C512-C256-C128-C64\n",
        "- Skip Connectionsï¼šç¼–ç å™¨ç¬¬iå±‚è¿æ¥åˆ°è§£ç å™¨ç¬¬n-iå±‚\n",
        "\n",
        "## è®­ç»ƒè®¾ç½®\n",
        "- ä¼˜åŒ–å™¨ï¼šAdam, lr=2e-4\n",
        "- å­¦ä¹ ç‡è°ƒåº¦ï¼šçº¿æ€§è¡°å‡ï¼ˆä»epoch 100å¼€å§‹ï¼‰\n",
        "- è®­ç»ƒè½®æ•°ï¼š200 epochs\n",
        "- Batch sizeï¼š1\n",
        "- æŸå¤±å‡½æ•°ï¼šä»…L1æŸå¤±\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siZaRHrv4kie"
      },
      "source": [
        "## Colabç¯å¢ƒè®¾ç½®\n",
        "\n",
        "### ğŸ“¦ æ•°æ®åŒæ­¥æ–¹æ¡ˆï¼ˆä¸‰é€‰ä¸€ï¼‰\n",
        "\n",
        "#### æ–¹æ¡ˆä¸€ï¼šGoogle Drive for Desktopï¼ˆæ¨èï¼Œæœ€ç®€å•ï¼‰\n",
        "1. **å®‰è£… Google Drive for Desktop**ï¼šhttps://www.google.com/drive/download/\n",
        "2. **è®¾ç½®åŒæ­¥æ–‡ä»¶å¤¹**ï¼š\n",
        "   - å°†é¡¹ç›®æ–‡ä»¶å¤¹æ·»åŠ åˆ°Google DriveåŒæ­¥ç›®å½•\n",
        "   - æœ¬åœ°ä¿®æ”¹ä¼šè‡ªåŠ¨åŒæ­¥åˆ°äº‘ç«¯\n",
        "   - åœ¨Colabä¸­ç›´æ¥ä½¿ç”¨åŒæ­¥åçš„æ–‡ä»¶ï¼Œæ— éœ€æ‰‹åŠ¨ä¸Šä¼ \n",
        "\n",
        "#### æ–¹æ¡ˆäºŒï¼šGit + GitHubï¼ˆæ¨èï¼Œé€‚åˆä»£ç ï¼‰\n",
        "1. **å°†ä»£ç æ¨é€åˆ°GitHub**ï¼ˆæ•°æ®æ–‡ä»¶ç”¨Git LFSæˆ–å•ç‹¬ä¸Šä¼ ï¼‰\n",
        "2. **åœ¨Colabä¸­ç›´æ¥å…‹éš†**ï¼šä»£ç ä¼šè‡ªåŠ¨ä»GitHubæ‹‰å–æœ€æ–°ç‰ˆæœ¬\n",
        "3. **ä¼˜ç‚¹**ï¼šç‰ˆæœ¬æ§åˆ¶ã€è‡ªåŠ¨åŒæ­¥ã€æ— éœ€å‹ç¼©ä¸Šä¼ \n",
        "\n",
        "#### æ–¹æ¡ˆä¸‰ï¼šæ‰‹åŠ¨ä¸Šä¼ ï¼ˆå¤‡é€‰ï¼‰\n",
        "å¦‚æœä½¿ç”¨æ‰‹åŠ¨ä¸Šä¼ ï¼Œè¯·å°†ä»¥ä¸‹æ–‡ä»¶å‹ç¼©ï¼š\n",
        "- `src/` ç›®å½•ï¼ˆæºä»£ç ï¼‰\n",
        "- `data/splits/cityscapes_split_seed42.json`ï¼ˆæ•°æ®åˆ’åˆ†æ–‡ä»¶ï¼‰\n",
        "- `data/processed/` ç›®å½•ï¼ˆå›¾åƒæ•°æ®ï¼Œå¯å‹ç¼©ä¸º `data_processed.zip`ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ ä½¿ç”¨è¯´æ˜\n",
        "\n",
        "**å¦‚æœä½¿ç”¨æ–¹æ¡ˆä¸€ï¼ˆGoogle DriveåŒæ­¥ï¼‰**ï¼š\n",
        "- ç¡®ä¿é¡¹ç›®æ–‡ä»¶å¤¹å·²åœ¨Google Driveä¸­åŒæ­¥\n",
        "- ç›´æ¥è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨åŒæ­¥çš„æ–‡ä»¶\n",
        "\n",
        "**å¦‚æœä½¿ç”¨æ–¹æ¡ˆäºŒï¼ˆGitHubï¼‰**ï¼š\n",
        "- åœ¨ä¸‹é¢çš„ä»£ç ä¸­è®¾ç½® `USE_GITHUB = True` å¹¶å¡«å†™ä»“åº“åœ°å€\n",
        "- ä»£ç ä¼šè‡ªåŠ¨å…‹éš†æœ€æ–°ç‰ˆæœ¬\n",
        "\n",
        "**å¦‚æœä½¿ç”¨æ–¹æ¡ˆä¸‰ï¼ˆæ‰‹åŠ¨ä¸Šä¼ ï¼‰**ï¼š\n",
        "- ä¸Šä¼ å‹ç¼©åŒ…åˆ°Google Drive\n",
        "- ä»£ç ä¼šè‡ªåŠ¨è§£å‹\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LATAbnzd4kie",
        "outputId": "028960bd-44b5-479b-e9b1-51f580906047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨æŒ‚è½½Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google DriveæŒ‚è½½å®Œæˆï¼\n",
            "\n",
            "ğŸ“¦ ä»GitHubå…‹éš†é¡¹ç›®: AltheD/Image-to-Image-Translation-Experiment\n",
            "âš ï¸  é¡¹ç›®ç›®å½•å·²å­˜åœ¨ï¼Œè·³è¿‡å…‹éš†\n",
            "\n",
            "ğŸ“¦ æ­£åœ¨æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…...\n",
            "âœ… torch å·²å®‰è£…\n",
            "âœ… torchvision å·²å®‰è£…\n",
            "âœ… pillow å·²å®‰è£…\n",
            "âœ… matplotlib å·²å®‰è£…\n",
            "âœ… numpy å·²å®‰è£…\n",
            "âœ… tqdm å·²å®‰è£…\n",
            "\n",
            "âœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼\n",
            "å½“å‰å·¥ä½œç›®å½•ï¼š/content/Image-to-Image-Translation-Experiment\n",
            "é¡¹ç›®æ ¹ç›®å½•ï¼š/content/Image-to-Image-Translation-Experiment\n",
            "åŒæ­¥æ–¹å¼ï¼šgithub\n",
            "\n",
            "ğŸ“‹ éªŒè¯é¡¹ç›®æ–‡ä»¶...\n",
            "âœ… æ¨¡å‹æ–‡ä»¶: src/models/unet_baseline.py\n",
            "âœ… æ•°æ®é›†æ–‡ä»¶: src/data/dataset.py\n",
            "âœ… æ•°æ®å˜æ¢æ–‡ä»¶: src/data/transforms.py\n",
            "âœ… æ•°æ®åˆ’åˆ†æ–‡ä»¶: data/splits/cityscapes_split_seed42.json\n",
            "\n",
            "ğŸ‰ æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Colabç¯å¢ƒè®¾ç½®ï¼šæ”¯æŒå¤šç§åŒæ­¥æ–¹æ¡ˆ\n",
        "# ============================================\n",
        "\n",
        "# å…ˆå¯¼å…¥ä¾èµ–\n",
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "# ========== é…ç½®åŒºåŸŸ ==========\n",
        "# é€‰æ‹©åŒæ­¥æ–¹æ¡ˆï¼š'github', 'drive_sync', 'manual'\n",
        "SYNC_METHOD = 'github'  # æˆ– 'drive_sync' æˆ– 'manual'\n",
        "\n",
        "# GitHubé…ç½®ï¼ˆå¦‚æœä½¿ç”¨æ–¹æ¡ˆäºŒï¼‰\n",
        "GITHUB_REPO = \"AltheD/Image-to-Image-Translation-Experiment\"  # æ›¿æ¢ä¸ºä½ çš„GitHubä»“åº“åœ°å€\n",
        "GITHUB_BRANCH = \"main\"  # æˆ– \"master\"\n",
        "\n",
        "# Google Driveé…ç½®ï¼ˆå¦‚æœä½¿ç”¨æ–¹æ¡ˆä¸€æˆ–ä¸‰ï¼‰\n",
        "DRIVE_PROJECT_DIR = Path(\"/content/drive/MyDrive/Image-to-Image-Translation-Experiment\")\n",
        "# ==============================\n",
        "\n",
        "COLAB_WORK_DIR = Path(\"/content/Image-to-Image-Translation-Experiment\")\n",
        "\n",
        "# 1. æŒ‚è½½Google Driveï¼ˆæ‰€æœ‰æ–¹æ¡ˆéƒ½éœ€è¦ï¼‰\n",
        "print(\"æ­£åœ¨æŒ‚è½½Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Google DriveæŒ‚è½½å®Œæˆï¼\")\n",
        "\n",
        "# 2. æ ¹æ®é€‰æ‹©çš„æ–¹æ¡ˆè®¾ç½®é¡¹ç›®\n",
        "if SYNC_METHOD == 'github':\n",
        "    # æ–¹æ¡ˆäºŒï¼šä»GitHubå…‹éš†\n",
        "    print(f\"\\nğŸ“¦ ä»GitHubå…‹éš†é¡¹ç›®: {GITHUB_REPO}\")\n",
        "    if COLAB_WORK_DIR.exists():\n",
        "        print(\"âš ï¸  é¡¹ç›®ç›®å½•å·²å­˜åœ¨ï¼Œæ‹‰å–æœ€æ–°ä»£ç \")\n",
        "        subprocess.run([\"git\", \"-C\", str(COLAB_WORK_DIR), \"pull\"], check=True)\n",
        "    else:\n",
        "        repo_url = f\"https://github.com/{GITHUB_REPO}.git\"\n",
        "        subprocess.run([\"git\", \"clone\", \"-b\", GITHUB_BRANCH, repo_url, str(COLAB_WORK_DIR)], check=True)\n",
        "        print(\"âœ… GitHubå…‹éš†å®Œæˆï¼\")\n",
        "\n",
        "    # æ£€æŸ¥æ•°æ®æ–‡ä»¶ï¼ˆGitHubé€šå¸¸ä¸åŒ…å«å¤§æ•°æ®æ–‡ä»¶ï¼‰\n",
        "    if not (COLAB_WORK_DIR / \"data\" / \"processed\").exists():\n",
        "        print(\"\\nâš ï¸  æ£€æµ‹åˆ°æ•°æ®æ–‡ä»¶ç¼ºå¤±ï¼Œå°è¯•ä»Google Driveå¤åˆ¶...\")\n",
        "        if (DRIVE_PROJECT_DIR / \"data\" / \"processed\").exists():\n",
        "            (COLAB_WORK_DIR / \"data\").mkdir(parents=True, exist_ok=True)\n",
        "            if (COLAB_WORK_DIR / \"data\" / \"processed\").exists():\n",
        "                if (COLAB_WORK_DIR / \"data\" / \"processed\").is_symlink():\n",
        "                    print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥å·²å­˜åœ¨\")\n",
        "                else:\n",
        "                    shutil.rmtree(COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                    os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                              COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                    print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥åˆ›å»ºå®Œæˆï¼\")\n",
        "            else:\n",
        "                os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                          COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥åˆ›å»ºå®Œæˆï¼\")\n",
        "        else:\n",
        "            print(\"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²ä¸Šä¼ åˆ°Google Drive\")\n",
        "\n",
        "    os.chdir(COLAB_WORK_DIR)\n",
        "\n",
        "elif SYNC_METHOD == 'drive_sync':\n",
        "    # æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨Google DriveåŒæ­¥çš„æ–‡ä»¶ï¼ˆç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€è§£å‹ï¼‰\n",
        "    print(\"\\nğŸ“ ä½¿ç”¨Google DriveåŒæ­¥çš„æ–‡ä»¶...\")\n",
        "    if not DRIVE_PROJECT_DIR.exists():\n",
        "        print(f\"âŒ æœªæ‰¾åˆ°é¡¹ç›®ç›®å½•: {DRIVE_PROJECT_DIR}\")\n",
        "        print(\"   è¯·ç¡®ä¿å·²å®‰è£…Google Drive for Desktopå¹¶åŒæ­¥é¡¹ç›®æ–‡ä»¶å¤¹\")\n",
        "    else:\n",
        "        print(f\"âœ… æ‰¾åˆ°é¡¹ç›®ç›®å½•: {DRIVE_PROJECT_DIR}\")\n",
        "        # åˆ›å»ºç¬¦å·é“¾æ¥æˆ–ç›´æ¥ä½¿ç”¨ï¼ˆå¦‚æœæ•°æ®åœ¨Driveä¸­ï¼‰\n",
        "        if not COLAB_WORK_DIR.exists():\n",
        "            COLAB_WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # å¤åˆ¶æºä»£ç ï¼ˆå°æ–‡ä»¶ï¼‰\n",
        "        if (DRIVE_PROJECT_DIR / \"src\").exists():\n",
        "            if (COLAB_WORK_DIR / \"src\").exists():\n",
        "                shutil.rmtree(COLAB_WORK_DIR / \"src\")\n",
        "            shutil.copytree(DRIVE_PROJECT_DIR / \"src\", COLAB_WORK_DIR / \"src\")\n",
        "            print(\"âœ… æºä»£ç å·²å¤åˆ¶\")\n",
        "\n",
        "        # æ•°æ®æ–‡ä»¶ä½¿ç”¨ç¬¦å·é“¾æ¥ï¼ˆèŠ‚çœç©ºé—´å’Œæ—¶é—´ï¼‰\n",
        "        (COLAB_WORK_DIR / \"data\").mkdir(parents=True, exist_ok=True)\n",
        "        if (DRIVE_PROJECT_DIR / \"data\" / \"splits\").exists():\n",
        "            (COLAB_WORK_DIR / \"data\" / \"splits\").mkdir(parents=True, exist_ok=True)\n",
        "            if not (COLAB_WORK_DIR / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\").exists():\n",
        "                shutil.copy2(DRIVE_PROJECT_DIR / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\",\n",
        "                            COLAB_WORK_DIR / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\")\n",
        "            print(\"âœ… æ•°æ®åˆ’åˆ†æ–‡ä»¶å·²å¤åˆ¶\")\n",
        "\n",
        "        if (DRIVE_PROJECT_DIR / \"data\" / \"processed\").exists():\n",
        "            if (COLAB_WORK_DIR / \"data\" / \"processed\").exists():\n",
        "                if not (COLAB_WORK_DIR / \"data\" / \"processed\").is_symlink():\n",
        "                    shutil.rmtree(COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                    os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                              COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "            else:\n",
        "                os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                          COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "            print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥å·²åˆ›å»º\")\n",
        "\n",
        "        os.chdir(COLAB_WORK_DIR)\n",
        "\n",
        "else:\n",
        "    # æ–¹æ¡ˆä¸‰ï¼šæ‰‹åŠ¨ä¸Šä¼ ï¼ˆè§£å‹zipæ–‡ä»¶ï¼‰\n",
        "    print(\"\\nğŸ“¦ ä½¿ç”¨æ‰‹åŠ¨ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆè§£å‹æ¨¡å¼ï¼‰...\")\n",
        "    COLAB_WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    os.chdir(COLAB_WORK_DIR)\n",
        "\n",
        "    # 3. è§£å‹é¡¹ç›®æ–‡ä»¶ï¼ˆä»…æ‰‹åŠ¨ä¸Šä¼ æ¨¡å¼éœ€è¦ï¼‰\n",
        "    project_zip = DRIVE_PROJECT_DIR / \"project.zip\"\n",
        "    src_zip = DRIVE_PROJECT_DIR / \"src.zip\"\n",
        "    data_splits_zip = DRIVE_PROJECT_DIR / \"data_splits.zip\"\n",
        "    data_processed_zip = DRIVE_PROJECT_DIR / \"data_processed.zip\"\n",
        "\n",
        "    def extract_if_needed(zip_path, target_dir, description):\n",
        "        \"\"\"å¦‚æœç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™è§£å‹zipæ–‡ä»¶\"\"\"\n",
        "        target_path = COLAB_WORK_DIR / target_dir\n",
        "        if not target_path.exists() or not any(target_path.iterdir()):\n",
        "            if zip_path.exists():\n",
        "                print(f\"æ­£åœ¨è§£å‹ {description}...\")\n",
        "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(COLAB_WORK_DIR)\n",
        "                print(f\"âœ… {description} è§£å‹å®Œæˆï¼\")\n",
        "            else:\n",
        "                print(f\"âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ° {zip_path}\")\n",
        "                print(f\"   è¯·ç¡®ä¿å·²ä¸Šä¼ æ–‡ä»¶åˆ°Google Driveï¼Œæˆ–æ‰‹åŠ¨è§£å‹åˆ° {target_path}\")\n",
        "        else:\n",
        "            print(f\"âœ… {description} å·²å­˜åœ¨ï¼Œè·³è¿‡è§£å‹\")\n",
        "\n",
        "    # è§£å‹æºä»£ç \n",
        "    if project_zip.exists():\n",
        "        extract_if_needed(project_zip, \".\", \"é¡¹ç›®æ–‡ä»¶\")\n",
        "    elif src_zip.exists():\n",
        "        extract_if_needed(src_zip, \"src\", \"æºä»£ç \")\n",
        "    else:\n",
        "        # å°è¯•ä»å·²å­˜åœ¨çš„ç›®å½•å¤åˆ¶\n",
        "        if (DRIVE_PROJECT_DIR / \"src\").exists():\n",
        "            print(\"æ­£åœ¨å¤åˆ¶æºä»£ç ç›®å½•...\")\n",
        "            if (COLAB_WORK_DIR / \"src\").exists():\n",
        "                shutil.rmtree(COLAB_WORK_DIR / \"src\")\n",
        "            shutil.copytree(DRIVE_PROJECT_DIR / \"src\", COLAB_WORK_DIR / \"src\")\n",
        "            print(\"âœ… æºä»£ç å¤åˆ¶å®Œæˆï¼\")\n",
        "        else:\n",
        "            print(\"âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°æºä»£ç æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„\")\n",
        "\n",
        "    # è§£å‹æ•°æ®åˆ’åˆ†æ–‡ä»¶\n",
        "    if data_splits_zip.exists():\n",
        "        extract_if_needed(data_splits_zip, \"data/splits\", \"æ•°æ®åˆ’åˆ†æ–‡ä»¶\")\n",
        "    elif (DRIVE_PROJECT_DIR / \"data\" / \"splits\").exists():\n",
        "        print(\"æ­£åœ¨å¤åˆ¶æ•°æ®åˆ’åˆ†æ–‡ä»¶...\")\n",
        "        (COLAB_WORK_DIR / \"data\" / \"splits\").mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(DRIVE_PROJECT_DIR / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\",\n",
        "                     COLAB_WORK_DIR / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\")\n",
        "        print(\"âœ… æ•°æ®åˆ’åˆ†æ–‡ä»¶å¤åˆ¶å®Œæˆï¼\")\n",
        "\n",
        "    # è§£å‹å›¾åƒæ•°æ®ï¼ˆå¦‚æœæ•°æ®è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨ç¬¦å·é“¾æ¥è€Œä¸æ˜¯å¤åˆ¶ï¼‰\n",
        "    if data_processed_zip.exists():\n",
        "        extract_if_needed(data_processed_zip, \"data/processed\", \"å›¾åƒæ•°æ®\")\n",
        "    elif (DRIVE_PROJECT_DIR / \"data\" / \"processed\").exists():\n",
        "        print(\"æ­£åœ¨åˆ›å»ºæ•°æ®ç›®å½•ç¬¦å·é“¾æ¥ï¼ˆèŠ‚çœç©ºé—´ï¼‰...\")\n",
        "        (COLAB_WORK_DIR / \"data\").mkdir(parents=True, exist_ok=True)\n",
        "        if (COLAB_WORK_DIR / \"data\" / \"processed\").exists():\n",
        "            if (COLAB_WORK_DIR / \"data\" / \"processed\").is_symlink():\n",
        "                print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥å·²å­˜åœ¨\")\n",
        "            else:\n",
        "                shutil.rmtree(COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                          COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "                print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥åˆ›å»ºå®Œæˆï¼\")\n",
        "        else:\n",
        "            os.symlink(DRIVE_PROJECT_DIR / \"data\" / \"processed\",\n",
        "                      COLAB_WORK_DIR / \"data\" / \"processed\")\n",
        "            print(\"âœ… æ•°æ®ç›®å½•ç¬¦å·é“¾æ¥åˆ›å»ºå®Œæˆï¼\")\n",
        "    else:\n",
        "        print(\"âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°å›¾åƒæ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„\")\n",
        "\n",
        "# 4. å®‰è£…ä¾èµ–åŒ…\n",
        "print(\"\\nğŸ“¦ æ­£åœ¨æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…...\")\n",
        "\n",
        "packages = [\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"pillow\",\n",
        "    \"matplotlib\",\n",
        "    \"numpy\",\n",
        "    \"tqdm\",\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package if package != \"pillow\" else \"PIL\")\n",
        "        print(f\"âœ… {package} å·²å®‰è£…\")\n",
        "    except ImportError:\n",
        "        print(f\"æ­£åœ¨å®‰è£… {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
        "        print(f\"âœ… {package} å®‰è£…å®Œæˆ\")\n",
        "\n",
        "print(\"\\nâœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
        "print(f\"å½“å‰å·¥ä½œç›®å½•ï¼š{os.getcwd()}\")\n",
        "print(f\"é¡¹ç›®æ ¹ç›®å½•ï¼š{COLAB_WORK_DIR}\")\n",
        "print(f\"åŒæ­¥æ–¹å¼ï¼š{SYNC_METHOD}\")\n",
        "\n",
        "# éªŒè¯å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "print(\"\\nğŸ“‹ éªŒè¯é¡¹ç›®æ–‡ä»¶...\")\n",
        "required_files = [\n",
        "    (\"src/models/unet_baseline.py\", \"æ¨¡å‹æ–‡ä»¶\"),\n",
        "    (\"src/data/dataset.py\", \"æ•°æ®é›†æ–‡ä»¶\"),\n",
        "    (\"src/data/transforms.py\", \"æ•°æ®å˜æ¢æ–‡ä»¶\"),\n",
        "    (\"data/splits/cityscapes_split_seed42.json\", \"æ•°æ®åˆ’åˆ†æ–‡ä»¶\"),\n",
        "]\n",
        "\n",
        "all_ok = True\n",
        "for file_path, description in required_files:\n",
        "    full_path = COLAB_WORK_DIR / file_path\n",
        "    if full_path.exists():\n",
        "        print(f\"âœ… {description}: {file_path}\")\n",
        "    else:\n",
        "        print(f\"âŒ {description} ç¼ºå¤±: {file_path}\")\n",
        "        all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\nğŸ‰ æ‰€æœ‰å¿…éœ€æ–‡ä»¶å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥åŒæ­¥è®¾ç½®\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zptPBV_n4kih",
        "outputId": "03188a33-3b05-404c-8cd8-23004dcdd0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "é¡¹ç›®æ ¹ç›®å½•ï¼š/content/Image-to-Image-Translation-Experiment\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥åº“\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆé€‚é…Colabç¯å¢ƒï¼‰\n",
        "# æ£€æµ‹æ˜¯å¦åœ¨Colabç¯å¢ƒä¸­è¿è¡Œ\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # åœ¨Colabä¸­ï¼Œä½¿ç”¨ä¹‹å‰è®¾ç½®çš„COLAB_WORK_DIR\n",
        "    try:\n",
        "        ROOT = COLAB_WORK_DIR\n",
        "    except NameError:\n",
        "        # å¦‚æœCOLAB_WORK_DIRæœªå®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„\n",
        "        ROOT = Path(\"/content/Image-to-Image-Translation-Experiment\")\n",
        "else:\n",
        "    # æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„\n",
        "    ROOT = Path(\"..\").resolve()\n",
        "\n",
        "sys.path.insert(0, str(ROOT))\n",
        "print(f\"é¡¹ç›®æ ¹ç›®å½•ï¼š{ROOT}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "from src.models.unet_baseline import UNetBaseline\n",
        "from src.data.dataset import CityscapesDataset\n",
        "from src.data.transforms import build_transform\n",
        "\n",
        "# è®¾ç½®è®¾å¤‡\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# æ•°æ®è·¯å¾„\n",
        "DATA_ROOT = ROOT / \"data\"\n",
        "SPLIT_INDEX = ROOT / \"data\" / \"splits\" / \"cityscapes_split_seed42.json\"\n",
        "OUTPUT_DIR = ROOT / \"outputs\" / \"unet_baseline\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdn0VJh24kii"
      },
      "source": [
        "## 1. æµ‹è¯•U-Netæ¨¡å‹æ¶æ„\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "5cPj-Jxk4kii",
        "outputId": "53af7748-3750-453e-f38f-56fe29467923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 3, 256, 256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'UNetBlock' object has no attribute 'dropout'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-714275382.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output shape: {output.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output range: [{output.min():.3f}, {output.max():.3f}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Image-to-Image-Translation-Experiment/src/models/unet_baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# ç¼–ç å™¨ï¼ˆä¿å­˜ä¸­é—´ç‰¹å¾ç”¨äºskip connectionsï¼‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# [B, 64, 128, 128]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [B, 128, 64, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [B, 256, 32, 32]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Image-to-Image-Translation-Experiment/src/models/unet_baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1965\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'UNetBlock' object has no attribute 'dropout'"
          ]
        }
      ],
      "source": [
        "# åˆ›å»ºæ¨¡å‹å¹¶æµ‹è¯•å‰å‘ä¼ æ’­\n",
        "model = UNetBaseline(in_channels=3, out_channels=3).to(device)\n",
        "model.eval()\n",
        "\n",
        "# æµ‹è¯•è¾“å…¥\n",
        "x = torch.randn(1, 3, 256, 256).to(device)\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "    print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
        "    print(f\"Expected range: [-1, 1] (Tanh activation)\")\n",
        "\n",
        "# è®¡ç®—å‚æ•°é‡\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNRWDFfY4kii"
      },
      "source": [
        "## 2. å‡†å¤‡æ•°æ®é›†ï¼ˆä¸‰ç§å¢å¼ºé…ç½®ï¼‰\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knr46mFt4kii"
      },
      "outputs": [],
      "source": [
        "# å®šä¹‰ä¸‰ç§å¢å¼ºé…ç½®\n",
        "aug_configs = {\n",
        "    \"none\": build_transform(\n",
        "        image_size=256,\n",
        "        jitter=False,\n",
        "        horizontal_flip=False,\n",
        "        color_jitter=None,\n",
        "        scale_range=None,\n",
        "        normalize_mode=\"tanh\"\n",
        "    ),\n",
        "    \"basic\": build_transform(\n",
        "        image_size=256,\n",
        "        jitter=True,\n",
        "        horizontal_flip=True,\n",
        "        color_jitter=None,\n",
        "        scale_range=None,\n",
        "        normalize_mode=\"tanh\"\n",
        "    ),\n",
        "    \"strong\": build_transform(\n",
        "        image_size=256,\n",
        "        jitter=True,\n",
        "        horizontal_flip=True,\n",
        "        color_jitter=(0.2, 0.2, 0.2, 0.05),\n",
        "        scale_range=(0.8, 1.2),\n",
        "        normalize_mode=\"tanh\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "# éªŒè¯é›†ä¸ä½¿ç”¨å¢å¼º\n",
        "val_transform = build_transform(\n",
        "    image_size=256,\n",
        "    jitter=False,\n",
        "    horizontal_flip=False,\n",
        "    color_jitter=None,\n",
        "    scale_range=None,\n",
        "    normalize_mode=\"tanh\"\n",
        ")\n",
        "\n",
        "print(\"æ•°æ®å¢å¼ºé…ç½®å·²å‡†å¤‡å®Œæˆï¼\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iERbSJ3S4kij"
      },
      "source": [
        "## 3. å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omguiJlx4kij"
      },
      "outputs": [],
      "source": [
        "# åŠ è½½ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–\n",
        "test_dataset = CityscapesDataset(\n",
        "    root=DATA_ROOT,\n",
        "    split=\"val\",\n",
        "    split_index=SPLIT_INDEX,\n",
        "    transform=None  # å…ˆä¸åº”ç”¨transformï¼Œçœ‹åŸå§‹å›¾åƒ\n",
        ")\n",
        "\n",
        "# è·å–åŸå§‹å›¾åƒ\n",
        "sample = test_dataset[0]\n",
        "label_orig = sample[\"label\"]\n",
        "photo_orig = sample[\"photo\"]\n",
        "\n",
        "# å¯è§†åŒ–åŸå§‹å›¾åƒå’Œä¸‰ç§å¢å¼ºé…ç½®\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "fig.suptitle(\"Data Augmentation Comparison\", fontsize=14)\n",
        "\n",
        "# ç¬¬ä¸€è¡Œï¼šLabel\n",
        "axes[0, 0].imshow(label_orig)\n",
        "axes[0, 0].set_title(\"Original Label\")\n",
        "axes[0, 0].axis(\"off\")\n",
        "\n",
        "for col, (aug_name, transform) in enumerate(aug_configs.items(), 1):\n",
        "    # åº”ç”¨å¢å¼º\n",
        "    label_aug, photo_aug = transform(label_orig.copy(), photo_orig.copy())\n",
        "\n",
        "    # è½¬æ¢ä¸ºå›¾åƒæ ¼å¼ï¼ˆtensor -> numpyï¼‰\n",
        "    def tensor_to_image(tensor):\n",
        "        if isinstance(tensor, torch.Tensor):\n",
        "            img = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "        else:\n",
        "            img = np.array(tensor)\n",
        "        if img.min() < 0:\n",
        "            img = (img + 1) / 2\n",
        "        img = np.clip(img, 0, 1)\n",
        "        return img\n",
        "\n",
        "    label_img = tensor_to_image(label_aug)\n",
        "    photo_img = tensor_to_image(photo_aug)\n",
        "\n",
        "    axes[0, col].imshow(label_img)\n",
        "    axes[0, col].set_title(f\"Label ({aug_name})\")\n",
        "    axes[0, col].axis(\"off\")\n",
        "\n",
        "    if col == 1:\n",
        "        axes[1, 0].imshow(photo_orig)\n",
        "        axes[1, 0].set_title(\"Original Photo\")\n",
        "        axes[1, 0].axis(\"off\")\n",
        "\n",
        "    axes[1, col].imshow(photo_img)\n",
        "    axes[1, col].set_title(f\"Photo ({aug_name})\")\n",
        "    axes[1, col].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"augmentation_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWqd0A7W4kij"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6PU0Ifs4kij"
      },
      "outputs": [],
      "source": [
        "def save_triplet(label, generated, ground_truth, save_path):\n",
        "    \"\"\"ä¿å­˜ä¸‰è”å›¾ï¼šLabel / Generated / Ground Truth\"\"\"\n",
        "    def tensor_to_image(tensor):\n",
        "        if tensor.dim() == 3:\n",
        "            img = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "        else:\n",
        "            img = tensor[0].permute(1, 2, 0).cpu().numpy()\n",
        "        if img.min() < 0:\n",
        "            img = (img + 1) / 2\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        return img\n",
        "\n",
        "    label_img = tensor_to_image(label)\n",
        "    gen_img = tensor_to_image(generated)\n",
        "    gt_img = tensor_to_image(ground_truth)\n",
        "\n",
        "    triplet = np.hstack([label_img, gen_img, gt_img])\n",
        "    Image.fromarray(triplet).save(save_path)\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for batch in pbar:\n",
        "        label = batch[\"label\"].to(device)\n",
        "        photo = batch[\"photo\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        generated = model(label)\n",
        "        loss = criterion(generated, photo)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    return total_loss / num_batches if num_batches > 0 else 0.0\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, dataloader, criterion, device, num_samples=10):\n",
        "    \"\"\"éªŒè¯å¹¶ä¿å­˜ä¸‰è”å›¾\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    saved_samples = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Validating\")\n",
        "    for batch in pbar:\n",
        "        label = batch[\"label\"].to(device)\n",
        "        photo = batch[\"photo\"].to(device)\n",
        "        name = batch[\"name\"]\n",
        "\n",
        "        generated = model(label)\n",
        "        loss = criterion(generated, photo)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        if saved_samples < num_samples:\n",
        "            save_path = OUTPUT_DIR / f\"sample_{saved_samples:02d}.png\"\n",
        "            save_triplet(label, generated, photo, save_path)\n",
        "            saved_samples += 1\n",
        "\n",
        "    return total_loss / num_batches if num_batches > 0 else 0.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtfQXu8_4kik"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UmiK_5s4kik"
      },
      "outputs": [],
      "source": [
        "# è®­ç»ƒé…ç½®\n",
        "aug_mode = \"none\"\n",
        "epochs = 200\n",
        "batch_size = 1\n",
        "lr = 2e-4\n",
        "start_decay_epoch = 100\n",
        "\n",
        "# åˆ›å»ºæ•°æ®é›†\n",
        "train_dataset = CityscapesDataset(\n",
        "    root=DATA_ROOT,\n",
        "    split=\"train\",\n",
        "    split_index=SPLIT_INDEX,\n",
        "    transform=aug_configs[aug_mode]\n",
        ")\n",
        "val_dataset = CityscapesDataset(\n",
        "    root=DATA_ROOT,\n",
        "    split=\"val\",\n",
        "    split_index=SPLIT_INDEX,\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# åœ¨Colabä¸­ï¼Œnum_workersåº”è¯¥è®¾ç½®ä¸º0ä»¥é¿å…å¤šè¿›ç¨‹é—®é¢˜\n",
        "# åœ¨æœ¬åœ°ç¯å¢ƒä¸­å¯ä»¥ä½¿ç”¨2æˆ–æ›´å¤š\n",
        "num_workers = 0 if IN_COLAB else 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# åˆ›å»ºæ¨¡å‹\n",
        "model = UNetBaseline(in_channels=3, out_channels=3).to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# å­¦ä¹ ç‡è°ƒåº¦\n",
        "def get_lr_scheduler(optimizer, num_epochs, start_decay_epoch):\n",
        "    def lr_lambda(epoch):\n",
        "        if epoch < start_decay_epoch:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 1.0 - (epoch - start_decay_epoch) / (num_epochs - start_decay_epoch)\n",
        "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "scheduler = get_lr_scheduler(optimizer, epochs, start_decay_epoch)\n",
        "\n",
        "# è®­ç»ƒå¾ªç¯\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f\"Starting training with augmentation: {aug_mode}\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = validate(model, val_loader, criterion, device, num_samples=10)\n",
        "\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {current_lr:.6f}\")\n",
        "\n",
        "        # ä¿å­˜checkpoint\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "        }, OUTPUT_DIR / f\"checkpoint_{aug_mode}_epoch_{epoch:03d}.pth\")\n",
        "\n",
        "# ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
        "torch.save({\n",
        "    \"epoch\": epochs,\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    \"train_losses\": train_losses,\n",
        "    \"val_losses\": val_losses,\n",
        "}, OUTPUT_DIR / f\"model_{aug_mode}_final.pth\")\n",
        "\n",
        "print(f\"\\nâœ… Training complete! ({aug_mode})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6GRFJy4kik"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPNkqXgg4kik"
      },
      "source": [
        "### 5.3 å¼ºå¢å¼ºé…ç½®\n",
        "\n",
        "> **æ³¨æ„**ï¼šè®­ç»ƒå¼ºå¢å¼ºé…ç½®æ—¶ï¼Œä¿®æ”¹ `aug_mode = \"strong\"`ã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUYm1SJ4kik"
      },
      "source": [
        "## 6. å¯è§†åŒ–è®­ç»ƒç»“æœ\n",
        "\n",
        "### 6.1 è®­ç»ƒæŸå¤±æ›²çº¿\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUfEAdlV4kik"
      },
      "outputs": [],
      "source": [
        "# åŠ è½½è®­ç»ƒå†å²ï¼ˆå¦‚æœæœ‰å¤šä¸ªé…ç½®ï¼Œå¯ä»¥åŠ è½½å¹¶å¯¹æ¯”ï¼‰\n",
        "# è¿™é‡Œå±•ç¤ºå¦‚ä½•ç»˜åˆ¶æŸå¤±æ›²çº¿\n",
        "\n",
        "# ç¤ºä¾‹ï¼šç»˜åˆ¶å•ä¸ªé…ç½®çš„æŸå¤±æ›²çº¿\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Loss\")\n",
        "plt.title(f\"Training History ({aug_mode})\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"L1 Loss (log scale)\")\n",
        "plt.yscale(\"log\")\n",
        "plt.title(f\"Training History - Log Scale ({aug_mode})\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / f\"training_curve_{aug_mode}.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VzpJ-sC4kik"
      },
      "source": [
        "### 6.2 ç”Ÿæˆç»“æœå¯è§†åŒ–\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwiYi4Co4kik"
      },
      "outputs": [],
      "source": [
        "# åŠ è½½ä¿å­˜çš„ä¸‰è”å›¾å¹¶å±•ç¤º\n",
        "import glob\n",
        "\n",
        "sample_images = sorted(glob.glob(str(OUTPUT_DIR / \"sample_*.png\")))[:6]\n",
        "\n",
        "if sample_images:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    fig.suptitle(f\"Generated Samples ({aug_mode})\", fontsize=14)\n",
        "\n",
        "    for idx, img_path in enumerate(sample_images):\n",
        "        row = idx // 3\n",
        "        col = idx % 3\n",
        "        img = Image.open(img_path)\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].set_title(f\"Sample {idx + 1}\")\n",
        "        axes[row, col].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR / f\"samples_{aug_mode}.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No sample images found. Run validation to generate samples.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGNkLotf4kil"
      },
      "source": [
        "## 7. æ¶ˆèå®éªŒå¯¹æ¯”ï¼ˆéœ€è¦å®Œæˆæ‰€æœ‰ä¸‰ç§é…ç½®åï¼‰\n",
        "\n",
        "> **æç¤º**ï¼šå®Œæˆä¸‰ç§å¢å¼ºé…ç½®çš„è®­ç»ƒåï¼Œå¯ä»¥åœ¨è¿™é‡Œå¯¹æ¯”ç»“æœï¼š\n",
        "> - åŠ è½½ä¸‰ç§é…ç½®çš„è®­ç»ƒå†å²\n",
        "> - å¯¹æ¯”æŸå¤±æ›²çº¿\n",
        "> - å¯¹æ¯”ç”Ÿæˆè´¨é‡\n",
        "> - è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆPSNRã€SSIMã€MAEï¼‰\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}